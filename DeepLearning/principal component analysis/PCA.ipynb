{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principle component analysis (PCA)\n",
    "Im Prinzip wird mit den Werten des Features und der jeweiligen Anzahl der features ein Vektor erstellt, der den Trend oder die _Wichtigkeit_ von den Daten darstellt.  \n",
    "  \n",
    "Im Prinzip wird in der folgenden Funktion ein Vektor (pca), Features und ein Startindex angenommen. Die Features werden entsprechend dem PCA transformiert, leicht verändert ab dem Startindex bis zum Ende (also der Wichtigkeit nach geordnet) und dann zurück transformiert. PCA wird auf den Original Zustand gebracht und die veränderten Daten ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import decomposition\n",
    "\n",
    "def generateData(pca, features, startIndex):\n",
    "    original = pca.components_.copy()\n",
    "    numberPrincipleComponents = pca.components_.shape[0]\n",
    "    before = pca.transform(features)\n",
    "    for i in range(startIndex, numberPrincipleComponents):\n",
    "        pca.components_[i,:] += np.random.normal(scale = 0.1, size = numberPrincipleComponents)\n",
    "    after = pca.inverse_transform(before)\n",
    "    pca.components_ = original.copy()\n",
    "    return after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(\"iris_features.npy\")\n",
    "y = np.load(\"iris_labels.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92461621 0.05301557 0.01718514 0.00518309]\n"
     ]
    }
   ],
   "source": [
    "N = 120\n",
    "x_train = x[:N]\n",
    "y_train = y[:N]\n",
    "x_test = x[N:]\n",
    "y_test = y[N:]\n",
    "pca = decomposition.PCA(n_components = 4)\n",
    "pca.fit(x)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Die ersten beide Werte erklären 97% der Varianz. Also verwenden wir fürs PCA nur die beiden letzten Komponenten.\n",
    "2. Ein set ist eine neue Sammlung von Samples\n",
    "3. Da ein set auf dem Original basiert, nimmt es die Form des Originals an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.\n",
    "start = 2 #2.\n",
    "numberSets = 10 \n",
    "numberSamples = x_train.shape[0] #3.\n",
    "newx = np.zeros((numberSets*numberSamples, x_train.shape[1]))\n",
    "newy = np.zeros(numberSets * numberSamples, dtype = \"uint8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die erste Iteration ist das Original und die nächsten fügen sich leicht verändert hinten ans Original an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(numberSets):\n",
    "    if (i == 0):\n",
    "        newx[0:numberSamples,:] = x_train\n",
    "        newy[0:numberSamples] = y_train\n",
    "    else:\n",
    "        newx[(i*numberSamples):(i*numberSamples+numberSamples),:] = \\\n",
    "            generateData(pca, x_train, start)\n",
    "        newy[(i*numberSamples):(i*numberSamples+numberSamples)] = y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idx = np.argsort(np.random.random(numberSets*numberSamples))\n",
    "newx = newx[idx]\n",
    "newy = newy[idx]\n",
    "print(newy.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.save(\"iris_train_features_augmented.npy\", newx)\n",
    "np.save(\"iris_train_labels_augmented.npy\", newy)\n",
    "np.save(\"iris_test_features_augmented.npy\", x_test)\n",
    "np.save(\"iris_test_labels_augmented.npy\", y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "954dccb827d9d98fab9d6ab8aad07d294372f56b78c45815942292b1b2f720a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
